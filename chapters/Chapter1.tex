\chapter{绪论}

\section{研究意义与背景}
深度估计作为三维计算机视觉领域的核心基础问题，旨在从二维图像中重建场景的几何特征，在过去十余年中经历了从手工特征建模到深度学习驱动的范式变迁\cite{Eigen,dpt}。
随着传感器技术与计算能力的提升，深度估计已成为智能无人系统实现环境感知与定位导航的关键技术：
在自动驾驶中，它为障碍物检测与路径规划提供必要的距离信息；在无人机技术中，它是实现自主避障与三维测绘的基础；在具身智能领域，深度估计则赋予了智能体感知空间结构并进行物理交互的能力。

从技术演进的维度看，单目深度估计的研究历程主要经历了三个阶段。初期阶段主要依赖手工设计的几何特征与先验假设 \cite{make3d}，
通过概率图模型整合图像的底层信息，但在复杂场景下的建模鲁棒性较差。
中期阶段随着卷积神经网络（CNN）的兴起，研究重心转向端到端的监督学习 \cite{dorn}，通过多尺度网络架构显著提升了像素级的预测精度。
现阶段则迈入了以大模型和多任务迁移为特征的新时期，
以 BEiT \cite{beit} 为代表的掩码图像建模预训练技术与 Vision Transformer (ViT) 架构的应用 \cite{dpt} 极大增强了模型对全局几何上下文的理解。

然而，现有的深度估计方法在非约束场景下的表现仍面临严峻挑战。由于单目深度估计本质上是一个不适定问题，存在固有的比例模糊性\cite{Eigen,uncertainty}，
神经网络往往倾向于通过学习训练集中的统计偏见（如物体位置与深度的相关性）来“走捷径”，而非真正理解场景的物理几何。这种策略导致模型过度拟合了特定数据集（如 KITTI 或 NYU Depth V2）的成像特性，使其对相机内参及拍摄视角具有极强的依赖性。一旦应用于光照剧变、极端天气或异质场景，由于领域鸿沟的存在，模型的预测精度往往会出现断崖式下降，限制了其在跨平台部署时的零样本迁移能力。

针对上述挑战，学术界开始探索一种新的研究范式：利用强泛化性的相对深度信息辅助绝对深度的估计\cite{midas}。 
相对深度虽然不具备物理单位，但其能通过海量异质数据的预训练，捕捉到稳健的几何拓扑关系与遮挡先验，展现出极佳的场景鲁棒性。

本文认为，融合相对深度的几何先验优势与绝对深度的尺度特性，是实现跨场景稳定感知的关键路径。 
通过设计一种能够解耦几何结构与物理尺度的预测框架，利用大模型提取的全局几何一致性来约束局部尺度恢复，可显著降低模型对特定相机内参的耦合。
这种方法旨在打破单目深度估计在未知场景下的精度瓶颈，为无人系统在复杂、全天候环境下的高精度感知提供新的理论支撑与技术方案。
\begin{figure}[!ht]    % [htbp] 表示建议 LaTeX 放置图片的位置（Here, Top, Bottom, Page）
    \centering          % 使图片居中
    \includegraphics[width=1.0\textwidth]{figures/ch1-drone.jpg} % 填入图片文件名（不带后缀也可以），width 指定宽度
    \caption{无人机} % 图片下方的标题
    \label{fig:ch1_drone} % 图片的唯一标签，用于正文引用
\end{figure}

\section{国内外研究现状}

\subsection{相对深度估计研究现状} 
单目深度估计根据输出表征的不同，通常可分为绝对深度估计与相对深度估计。绝对深度估计旨在恢复具有明确物理尺度的度量距离，
但在非约束场景下常面临严峻的尺度模糊性挑战；而相对深度估计则侧重于建模场景内物体的几何序关系，在复杂环境及跨领域迁移中展现出更强的鲁棒性。

相对深度特征的建模最早可追溯至 Saxena 等人\cite{make3d}的研究，该工作首次利用马尔可夫随机场（MRF）建模像素块间的空间相关性，
奠定了几何建模基础。2016年，Chen 等人\cite{Chen2016}真正将“相对深度估计”确立为一个独立的研究命题，
证明了通过人类标注的像素对排序先验（Ranking Perception）即可实现复杂场景下的深度感知。
随后，Ranftl 等人\cite{midas}正式提出了跨数据集混合训练方案，通过尺度与平移不变损失函数（Scale-and-shift-invariant Loss），
极大提升了模型的零样本（Zero-shot）泛化能力。与此同时，Yin 等人 \cite{leres} 进一步探索了利用多种异构数据集恢复 3D 场景形状的方法，
有效增强了模型对复杂几何布局的适应性。

进入2023年后，相对深度估计在“视觉基础模型”的推动下取得了突破性进展。以 DINOv2\cite{dinov2} 为代表的大规模自监督预训练模型证明，
强力的语义特征与场景的几何拓扑存在高度一致性。在此基础上，
Depth Anything\cite{depthanything} 系列工作通过海量无标签数据的判别式训练，
实现了在任意“野外”场景下极具鲁棒性的深度结构恢复。这些工作不仅提供了高精度的深度图输出，
更重要的是构建了一个包含丰富几何纹理与空间上下文的特征表示空间（Feature Representation Space）。
此外，针对深度图细节丢失的问题，Boosting 架构 \cite{boosting} 通过多尺度切片合并策略实现了高分辨率深度细节的恢复；
而近期出现的 Marigold \cite{marigold} 则开创性地利用预训练扩散模型（Diffusion Models）的生成先验，将深度估计转化为图像生成任务，
在零样本场景下展现了极高的几何一致性与纹理精度。

尽管上述工作在几何结构的稳健性方面取得了显著突破，但由于相对深度输出缺乏真实的物理尺度信息（Metric Scale），
导致其在自动驾驶、无人机避障等绝对距离敏感任务中应用受限。因此，如何有效提取并利用相对深度模型中蕴含的强泛化特征块（Feature Blocks），将其作为先验引导来实现高精度的尺度恢复，已成为当前打通“几何结构”与“物理度量”逻辑鸿沟的关键研究方向。

\subsection{绝对深度估计研究现状}
绝对深度估计（Metric Depth Estimation）旨在建立图像特征与真实物理距离之间的回归映射。
早期研究如 Eigen 等人\cite{eigen2014}利用多尺度 CNN 实现了端到端的深度回归，奠定了深度学习在该领域的基础。
随后，为了解决连续值回归收敛困难的问题，Fu 等人\cite{dorn}提出了深度序数回归网络（DORN），
通过离散化策略将回归任务转化为有序分类，显著提升了特定数据集上的绝对数值精度。在真值获取方面，
针对激光雷达数据稀疏的挑战，Godard 等人\cite{monodepth2}提出了基于光度一致性约束的自监督学习范式，极大拓宽了应用边界。

进入“基础模型”时代以来，单目深度估计正经历从特定场景拟合向零样本泛化（Zero-shot Generalization）的范式转变。 
以 Depth Anything\cite{depthanything} 和 Metric3D\cite{metric3d} 为代表的工作，通过大规模弱监督预训练与数据蒸馏技术，
证明了利用海量无标签数据学习稳健几何表示的可能性。
随后，Metric3D-v2 \cite{metric3d_v2} 进一步通过万能相机模型（Canonical Camera Space）解决了跨数据集训练中的标签歧义问题。
然而，即便在基础模型的支撑下，现有的绝对深度估计工作仍面临以下严峻挑战：

首先，模型对相机内参及场景分布存在深层的“尺度-语义耦合”误区。 \cite{unidepth}的研究深刻指出，现有的绝对深度预测框架往往将场景几何结构与物理尺度混合建模，
导致模型倾向于通过过拟合训练集中特定相机的成像特性（如焦距、安装高度）以及常见物体的先验尺寸（如车辆、人高）来推断距离，
而非基于纯粹的投影几何关系。这种统计过拟合（Statistical Overfitting）导致模型极易受到单目歧义性的干扰：
一旦测试环境的焦距或传感器尺寸发生变化，预测结果便会产生剧烈的尺度漂移，无法实现真正的物理一致性。

其次，现有工作对相对深度所蕴含的稳健几何先验利用不足。 从数学本质上看，绝对深度预测是一个受限于相机内参的“病态问题”，
而相对深度由于具备尺度不变性（Scale-invariant），在捕捉物体边缘、空间拓扑及遮挡关系方面表现出极强的泛化潜能。遗憾的是，
多数绝对深度研究仍倾向于构建从图像到绝对数值的直接映射（Direct Mapping）。这种“一步到位”的回归范式往往试图让模型同时学习“复杂的几何感知”与“脆弱的绝对回归”，导致模型在面对异质场景时，容易为了拟合数值精度而丧失基本的几何结构约束，产生结构畸变或物体边缘模糊。

% ！！！这一段肯定需要改。最好是等 2 3 4章写完之后再写。
目前，如何在高精度度量需求下实现几何结构与绝对尺度的深度解耦与耦合，已成为学术界关注的焦点。 
尽管 ZoeDepth\cite{zoedepth} 等工作尝试引入相对深度特征，但其复杂的端到端训练策略仍难以完全摆脱尺度耦合的影响。
鉴于此，探讨如何将具有强泛化力的相对深度作为“几何基座”，并通过轻量化的映射机制恢复物理尺度，
对于构建全天候、高可靠的无人系统具有重要的学术意义与应用价值。



