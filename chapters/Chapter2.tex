\chapter{基于相对深度引导的映射模块}
\section{引言}
随着具身智能技术的普及，单目深度估计（MDE）已成为自动驾驶与机器人感知的核心环节。按照表征形式，
MDE 可分为相对深度估计与绝对深度（Metric Depth）估计，后者因能恢复具备真实物理尺度的像素级距离，
成为系统从“视觉感知”迈向“物理交互”的关键桥梁。在避障规划、目标抓取及视觉 SLAM 尺度恢复等任务中，
绝对尺度信息提供了不可或缺的几何度量约束。
相比激光雷达等昂贵设备，单目绝对深度估计凭借低成本与高灵活性，已成为构建全场景无人系统感知的核心基石。

如前文所述，从单幅图像推算绝对深度本质上是一个典型的“不适定问题”（Ill-posed Problem）。 
目前主流的单目绝对深度估计多采用端到端的直接回归范式，这种“一步到位”的映射机制使得模型不可避免地陷入尺度信息与几何结构的强耦合困境。
在这种机制下，模型往往过度依赖训练集中的语义先验（如物体的平均尺寸）来推断距离，而非理解真正的投影几何关系。
这导致模型在面对异质场景或相机内参发生波动时，极易产生剧烈的尺度漂移（Scale Drift），并导致物体边缘与空间布局的一致性受损。

值得注意的是，现有的绝对深度估计工作大多倾向于构建从图像特征到物理数值的直接线性或非线性映射，
这种粗放的回归方式忽略了相对深度中蕴含的稳健几何拓扑约束。由于绝对深度真值（Ground Truth）通常由稀疏的激光雷达获取，
且覆盖场景有限，模型在拟合有限的数值分布时，容易丧失对物体间细粒度几何序关系的把握。这导致模型在处理复杂场景时，
虽然能在统计数值上逼近真值，但其三维空间结构常发生畸变，无法满足高精度导航对环境结构化的严苛要求。

然而，现有的绝对深度估计工作大多倾向于构建从图像到物理数值的直接映射，
这种“一步到位”的粗放回归方式往往忽略了相对深度中蕴含的稳健几何拓扑约束。这导致模型在处理复杂场景时，
虽然能在数值上逼近真值，但其空间结构常发生畸变，且极易受相机参数波动的干扰。

针对上述挑战，本章提出了一种融合相对深度特征先验的二阶段解构式绝对深度估计方法。
该方法的核心逻辑在于将绝对深度估计任务解构为“结构感知”与“尺度适配”两个独立且互补的环节。
第一阶段利用具有强泛化力的预训练基础模型提取尺度不变的相对几何特征；第二阶段则通过一个轻量化映射模块，
利用多尺度特征块（Feature Blocks）中丰富的上下文信息引导模型完成从相对空间到物理尺度的精准转换。
这种解耦设计不仅能最大限度保留基础模型在“野外”环境下的结构泛化力，
更通过特征驱动的映射机制实现了物理尺度的精确对齐，为构建高鲁棒性的绝对深度感知系统提供了新思路。

\section{模型总体架构设计}

% 感觉图片里字有点小了。另外 不知道图片中英文好不好
\begin{figure}[htbp]
    \centering
    \begin{adjustbox}{center} % 强制相对于页面中心对齐
        \includegraphics[width=1.2\textwidth]{figures/主结构-最新drawio.drawio.pdf}
    \end{adjustbox}
    \caption{单目深度估计任务解构与特征提取框架}
    \label{fig:model_arch}
\end{figure}

本章所设计的绝对深度估计模型采用了任务解构的二阶段架构，旨在充分利用预训练基础模型的几何结构泛化能力，
并通过轻量化的度量映射分支实现物理尺度的精准恢复。模型总体架构如图\ref{fig:model_arch}所示，主要由特征提取编码器（Encoder）、
相对深度估计模块（Relative Estimation Module）以及度量深度估计模块（Metric Estimation Module）三部分组成。

\subsection{任务解构与特征提取}
为了从根本上解决单目绝对深度估计中由于投影歧义性导致的尺度与结构强耦合问题，
本文将深度恢复过程解构为“结构感知”与“尺度适配”两个解耦的子任务。
该设计旨在利用大规模预训练模型（如 DPT-BEiT 或 MiDaS 系列）的几何泛化能力，为绝对尺度的恢复提供稳健的拓扑约束。

在特征提取阶段，系统采用统一的共享编码器（Shared Encoder）作为底层基座。
对于输入的单幅 RGB 图像 $I \in \mathbb{R}^{3 \times H \times W}$，编码器通过分层表征学习提取出具有异构物理意义的特征。
如公式 \ref{eq:encoder} 所示：
\begin{equation}
    \{T, F\} = \text{Encoder}(I)
    \label{eq:encoder}
\end{equation}
其中，$T$ 为蕴含全局几何上下文的标记向量（Tokens）；$F = \{f_1, f_2, f_3, f_4\}$ 为多层级空间特征块（Feature Blocks），
对应于代码实现中不同层级的瓶颈层特征与解码块输出，承载了丰富的局部空间细节。

这种多路输出设计实现了任务驱动的特征分配逻辑。第一阶段相对估计分支利用标记向量 $T$ 构建场景的宏观拓扑，
确保深度图在几何序关系与物体边缘上的一致性；第二阶段度量映射分支则通过级联的投影器（Projector）处理特征块 $F$，
并利用局部特征块引导深度分桶（Bins）的自适应动态调整。

相较于传统的端到端直接回归范式，这种解构设计能够有效缓解单目深度估计的不适定性（Ill-posedness）。
通过在特征提取阶段将语义先验与尺度特征进行分离，模型能够有效抑制由于相机内参波动或异质场景切换带来的尺度漂移现象。这种解耦机制确保了模型在恢复物理尺度的同时，
能够最大限度保留基础模型所提供的强泛化几何结构，从而兼顾了预测结果的数值准确性与空间合理性。

\subsection{相对几何结构感知分支}

在单目深度估计任务中，建立稳健的几何拓扑关系是恢复绝对度量维度的前提。
本章所设计的相对几何结构感知分支旨在不考虑绝对物理尺寸的情况下，利用大规模预训练模型捕获的深层语义特征，
重构场景内物体的相对位置关系。该分支的输入为共享编码器输出的全局标记向量（Tokens）$\mathbf{T}$，
如公式 \ref{eq:rel_branch} 所示：
\begin{equation}
    D_{rel} = \Psi_{\text{rel}}(\mathbf{T})
    \label{eq:rel_branch}
\end{equation}
其中，$\Psi_{\text{rel}}$ 表示相对深度估计映射函数。

标记向量 $\mathbf{T}$ 进入相对估计模块后，首先通过多层感知机（MLP）进行维度对齐与特征压缩，
随后进入自注意力机制（Self-Attention）层进行长程依赖建模。自注意力机制的引入使得模型能够摆脱局部感受野的限制，
通过计算全图范围内的特征相关性，实现对场景宏观布局的深度理解。
这种全局建模能力对于识别复杂的物体间拓扑关系、处理大面积平坦区域以及跨越遮挡边界获取一致的几何先验至关重要。

该分支最终输出一张尺度不变的相对深度图 $D_{rel}$。该图能够精确捕获物体的轮廓细节、场景平面的斜率以及物体间的相互遮挡序关系。
尽管其数值不具备物理含义，但 $D_{rel}$ 提供的几何稳定性为下一阶段的尺度适配任务奠定了坚实基础。
通过将深度估计任务的第一阶段聚焦于几何拓扑的构建，模型能够显著增强在非约束场景下的泛化能力，
为后续实现精确的“结构-度量”映射提供可靠的几何度量锚点。

\subsection{绝对深度对齐分支}
