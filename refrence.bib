
% --- 阶段1：初期几何特征与先验 ---
@article{make3d,
  title={Make3d: Learning 3d scene structure from a single still image},
  author={Saxena, Ashutosh and Sun, Min and Ng, Andrew Y},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={31},
  number={5},
  pages={824--840},
  year={2008}
}

% --- 阶段2：CNN 时代的开创性工作 (Eigen 是深度学习深度估计的鼻祖) ---
@article{Eigen,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  journal={Advances in neural information processing systems (NeurIPS)},
  volume={27},
  year={2014}
}

% --- 阶段3：Vision Transformer (ViT) 与大模型 ---
@inproceedings{dpt,
  title={Vision transformers for dense prediction},
  author={Ranftl, René and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={12173--12183},
  year={2021}
}

% --- 比例模糊性与不适定问题 ---
@inproceedings{uncertainty,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2017}
}

% --- 相对深度与强泛化性 (MiDaS 是相对深度估计的标杆) ---
@article{midas,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Ranftl, René and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2020}
}

@inproceedings{dorn,
  title={Deep ordinal regression network for monocular depth estimation},
  author={Fu, Huan and Gong, Mingming and Wang, Chaohui and Batmanghelich, Kayhan and Tao, Dacheng},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
  pages={2002--2011},
  year={2018}
}

@inproceedings{beit,
  title={{BEiT}: {BERT} Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022}
}

@article{leres,
  title={Learning to recover 3D scene shape from a single image},
  author={Yin, Wei and Liu, Yifan and Shen, Chunhua and Yan, Youliang},
  journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{metric3d,
  title={Metric3D: Towards Zero-shot Metric Depth Prediction via Large-scale Multi-dataset Training},
  author={Yin, Wei and Zhang, Chi and Chen, Hao and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{boosting,
  title={Boosting Monocular Depth Estimation Models to High Resolution},
  author={Miangoleh, S Mahdi and Szeliski, Richard and Akbari, Habib and Wang, Yangzhou},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}



@inproceedings{Chen2016,
  title={Single-image depth perception in the wild},
  author={Chen, Weifeng and Fu, Zhao and Yang, Dawei and Deng, Jia},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS)},
  pages={730--738},
  year={2016}
}

@inproceedings{eigen2014,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2014}
}

@inproceedings{monodepth2,
  title={Digging into self-supervised monocular depth estimation},
  author={Godard, Cl{\'e}ment and Mac Aodha, Oisin and Firman, Michael and Brostow, Gabriel J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019}
}

% 1. Depth Anything (基础模型 V1, CVPR 2024)
@inproceedings{depthanything,
  title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

% 2. Metric3D v2 (绝对尺度估计的当前 SOTA, TPAMI 2024/2025)
@article{metric3d_v2,
  title={Metric3D v2: A Versatile Monocular Geometric Foundation Model for Zero-shot Metric Depth and Surface Normal Estimation},
  author={Yin, Wei and Zhang, Chi and Chen, Hao and Sun, Zhipeng and Wang, Kaixuan and Chen, Bin and Sun, Hanpeng and Jia, Jiaya and Shen, Chunhua},
  journal={arXiv preprint arXiv:2403.14611},
  year={2024}
}

% 3. ZoeDepth (二阶段相对转绝对的开创性工作, arXiv 2023)
% 这是证明“利用相对深度做绝对深度”可行性的重要参考文献
@article{zoedepth,
  title={ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth},
  author={Bhat, Shariq Farooq and Birkl, Reiner and Bieneck, Diana and Susstrunk, Sabine and Ranftl, Rene},
  journal={arXiv preprint arXiv:2302.12288},
  year={2023}
}

% 4. DINOv2 (目前所有顶级深度估计模型都在用的特征提取器, arXiv 2023)
@article{dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Vasiljevic, Vasil and Sun, Peryot and Ferrara, Piotr and Buslaev, Artem and Mathou, Benjamin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

% 5. Marigold (CVPR 2024, 证明了生成式先验对几何结构的强大保持能力)
@inproceedings{marigold,
  title={Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
  author={Ke, Bingxin and Obukhov, Anton and Huang, Shengyu and Metzger, Nando and Daudt, Rodrigo Caye and Schindler, Konrad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

% 6. UniDepth (CVPR 2024, 专门讨论相机内参解耦的工作)
@inproceedings{unidepth,
  title={UniDepth: Isolating Depth from Camera Parameters in One-Stage Anticipation},
  author={Piccinelli, Luigi and Yang, Yung-Hsu and Sakaridis, Christos and Segu, Mattia and Sini, Pier Luigi and Van Gool, Luc and Guizilini, Vitor},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}