% !TEX root = ../main.tex
\chapter{绪论}

\section{研究意义与背景}
深度估计作为三维计算机视觉领域的核心基础问题，旨在从二维图像中重建场景的几何特征，在过去十余年中经历了从手工特征建模到深度学习驱动的范式变迁\cite{Eigen,dpt}。
随着传感器技术与计算能力的提升，深度估计已成为智能无人系统实现环境感知与定位导航的关键技术：
在自动驾驶中，它为障碍物检测与路径规划提供必要的距离信息；在无人机技术中，它是实现自主避障与三维测绘的基础；在具身智能领域，深度估计则赋予了智能体感知空间结构并进行物理交互的能力。

从技术演进的维度看，单目深度估计的研究历程主要经历了三个阶段。初期阶段主要依赖手工设计的几何特征与先验假设 \cite{make3d}，
通过概率图模型整合图像的底层信息，但在复杂场景下的建模鲁棒性较差。
中期阶段随着卷积神经网络（CNN）的兴起，研究重心转向端到端的监督学习 \cite{dorn}，通过多尺度网络架构显著提升了像素级的预测精度。
现阶段则迈入了以大模型和多任务迁移为特征的新时期，Vision Transformer (ViT) 等架构的应用 \cite{dpt} 极大增强了模型对全局几何上下文的理解。

然而，现有的深度估计方法在非约束场景下的表现仍面临严峻挑战。由于单目深度估计本质上是一个不适定问题，存在固有的比例模糊性\cite{Eigen,uncertainty}，
神经网络往往倾向于通过学习训练集中的统计偏见（如物体位置与深度的相关性）来“走捷径”，而非真正理解场景的物理几何。这种策略导致模型过度拟合了特定数据集（如 KITTI 或 NYU Depth V2）的成像特性，使其对相机内参及拍摄视角具有极强的依赖性。一旦应用于光照剧变、极端天气或异质场景，由于领域鸿沟的存在，模型的预测精度往往会出现断崖式下降，限制了其在跨平台部署时的零样本迁移能力。

针对上述挑战，学术界开始探索一种新的研究范式：利用强泛化性的相对深度信息辅助绝对深度的估计\cite{midas}。 
相对深度虽然不具备物理单位，但其能通过海量异质数据的预训练，捕捉到稳健的几何拓扑关系与遮挡先验，展现出极佳的场景鲁棒性。

本文认为，融合相对深度的几何先验优势与绝对深度的尺度特性，是实现跨场景稳定感知的关键路径。 
通过设计一种能够解耦几何结构与物理尺度的预测框架，利用大模型提取的全局几何一致性来约束局部尺度恢复，可显著降低模型对特定相机内参的耦合。
这种方法旨在打破单目深度估计在未知场景下的精度瓶颈，为无人系统在复杂、全天候环境下的高精度感知提供新的理论支撑与技术方案。
\begin{figure}[!ht]    % [htbp] 表示建议 LaTeX 放置图片的位置（Here, Top, Bottom, Page）
    \centering          % 使图片居中
    \includegraphics[width=1.0\textwidth]{figures/ch1-drone.jpg} % 填入图片文件名（不带后缀也可以），width 指定宽度
    \caption{无人机} % 图片下方的标题
    \label{fig:ch1_drone} % 图片的唯一标签，用于正文引用
\end{figure}

\section{国内外研究现状}
% \subsection{相对深度估计研究现状0}
% 单目深度估计根据输出表征的不同，通常可分为绝对深度估计与相对深度估计。
% 绝对深度估计旨在恢复具有明确物理尺度的度量距离，但在非约束场景下常面临严峻的尺度模糊性挑战；
% 而相对深度估计则侧重于建模场景内物体的几何序关系，在复杂环境及跨领域迁移中展现出更强的鲁棒性。
% 相对深度特征的建模最早可追溯至 Saxena 等人\cite{make3d}的研究，虽然其核心目标是恢复场景的三维结构，
% 但该工作首次大规模利用马尔可夫随机场（Markov Random Field, MRF）来建模像素块间的空间相关性与相对位置关系，为后续相对深度概念的提出奠定了几何建模基础。
% 2016年，Chen 等人\cite{Chen2016}在《Single-Image Depth Perception in the Wild》中真正将“相对深度估计”确立为一个独立的研究命题。
% 该工作证明了深度信息可以脱离昂贵的传感器真值，通过人类标注的像素对排序先验（Ranking Perception）进行端到端训练，实现了在自然界复杂场景下的深度感知。
% 随后，Ranftl 等人\cite{midas}进一步完善了该范式，正式提出了跨数据集混合训练方案。
% 针对电影、激光雷达、虚拟游戏等异质数据集绝对单位不统一的问题，该研究通过尺度与平移不变的损失函数（Scale-and-shift-invariant Loss），
% 将多元数据统一在相对深度框架下进行联合训练，极大地提升了模型的零样本（Zero-shot）泛化能力。
% 尽管上述工作在几何结构的稳健性方面取得了显著突破，但由于相对深度输出缺乏真实的物理尺度信息（Metric Scale），导致其在自动驾驶、无人机避障等对绝对距离高度敏感的实际任务中应用受限。

\subsection{相对深度估计研究现状} 
单目深度估计根据输出表征的不同，通常可分为绝对深度估计与相对深度估计。绝对深度估计旨在恢复具有明确物理尺度的度量距离，
但在非约束场景下常面临严峻的尺度模糊性挑战；而相对深度估计则侧重于建模场景内物体的几何序关系，在复杂环境及跨领域迁移中展现出更强的鲁棒性。

相对深度特征的建模最早可追溯至 Saxena 等人\cite{make3d}的研究，该工作首次利用马尔可夫随机场（MRF）建模像素块间的空间相关性，
奠定了几何建模基础。2016年，Chen 等人\cite{Chen2016}真正将“相对深度估计”确立为一个独立的研究命题，
证明了通过人类标注的像素对排序先验（Ranking Perception）即可实现复杂场景下的深度感知。
随后，Ranftl 等人\cite{midas}正式提出了跨数据集混合训练方案，通过尺度与平移不变损失函数（Scale-and-shift-invariant Loss），
极大提升了模型的零样本（Zero-shot）泛化能力。

进入2023年后，相对深度估计在“视觉基础模型”的推动下取得了质的飞跃。 以 DINOv2\cite{dinov2} 为代表的大规模自监督预训练模型证明，
强力的语义特征与场景的几何拓扑存在高度一致性。在此基础上，
Depth Anything\cite{depthanything} 系列工作通过海量无标签数据的判别式训练，
实现了在任意“野外”场景下极具鲁棒性的深度结构恢复。这些工作不仅提供了高精度的深度图输出，
更重要的是构建了一个包含丰富几何纹理与空间上下文的特征表示空间（Feature Representation Space）。

尽管上述工作在几何结构的稳健性方面取得了显著突破，但由于相对深度输出缺乏真实的物理尺度信息（Metric Scale），
导致其在自动驾驶、无人机避障等绝对距离敏感任务中应用受限。因此，如何有效提取并利用相对深度模型中蕴含的强泛化特征块（Feature Blocks），将其作为先验引导来实现高精度的尺度恢复，已成为当前打通“几何结构”与“物理度量”逻辑鸿沟的关键研究方向。

% \subsection{绝对深度估计研究现状0}
% 绝对深度估计（Metric Depth Estimation）旨在直接建立图像特征与物理距离之间的回归映射。早期研究主要聚焦于如何在受限场景下提升度量精度。Eigen 等人\cite{eigen2014}首次利用多尺度卷积神经网络实现了端到端的深度回归，奠定了深度学习在该领域的基础。随后，为了解决连续值回归收敛困难的问题，Fu 等人\cite{dorn}提出了深度序数回归网络（DORN），通过间隔递增离散化策略将回归任务转化为有序分类任务，显著提升了模型在特定数据集上的绝对数值精度。

% 在真值获取方面，针对激光雷达数据稀疏且昂贵的挑战，Godard 等人\cite{monodepth2}提出了自监督学习范式，利用视频序列间的光度一致性作为约束，
% 极大拓宽了绝对深度估计的应用边界。然而，无论是全监督还是自监督方法，现有的绝对深度估计工作仍面临以下严峻挑战：

% 首先，模型对相机内参及场景分布存在严重的“尺度耦合”。
% 现有的绝对深度预测框架往往将场景几何结构与物理尺度混合建模，导致模型极易过拟合于特定相机的成像特性。
% 一旦测试环境的焦距、拍摄高度与训练集存在差异，预测结果便会产生剧烈的尺度偏移。

% 其次，现有工作对相对深度所蕴含的稳健几何先验利用不足。虽然相对深度在建模物体遮挡与空间拓扑方面具有天然优势，但多数绝对深度估计方法仍尝试从头学习像素级的数值映射，
% 而忽视了相对深度作为强力几何约束的潜力。
% 这导致现有模型在面对光照剧变或异质场景时，由于缺乏稳健的几何结构感知，其泛化能力始终无法满足全天候、全场景无人系统的部署需求。

% 其次，现有工作在追求数值精度时，往往忽视了相对深度（Relative Depth）所蕴含的稳健几何先验。从特征表示的角度看，
% 绝对深度预测是一个典型的“病态问题”，受限于相机内参和场景分布的强耦合；而相对深度由于具备尺度不变性（Scale-invariant），
% 在捕捉物体轮廓、空间拓扑及遮挡关系方面表现出极强的泛化潜能。

% 遗憾的是，多数现有的绝对深度研究仍倾向于构建从图像到绝对数值的直接映射（Direct Mapping），这种“一步到位”的回归范式导致模型在未知环境下容易丢失基本的几何结构约束。这种对相对几何信息利用的缺位，使得绝对深度估计模型在面对高动态、异质场景时，难以兼顾“尺度的准确性”与“结构的合理性”。
% 鉴于此，深入探讨相对深度估计的发展脉络，并挖掘其作为绝对深度估计“几何基座”的潜力，具有重要的研究价值。
% 尽管已有少量工作尝试引入尺度不变特征，但如何在高精度度量需求下实现两者的深度耦合，仍是当前亟待解决的问题。

\subsection{绝对深度估计研究现状}
绝对深度估计（Metric Depth Estimation）旨在建立图像特征与真实物理距离之间的回归映射。
早期研究如 Eigen 等人\cite{eigen2014}利用多尺度 CNN 实现了端到端的深度回归，奠定了深度学习在该领域的基础。
随后，为了解决连续值回归收敛困难的问题，Fu 等人\cite{dorn}提出了深度序数回归网络（DORN），
通过离散化策略将回归任务转化为有序分类，显著提升了特定数据集上的绝对数值精度。在真值获取方面，
针对激光雷达数据稀疏的挑战，Godard 等人\cite{monodepth2}提出了基于光度一致性约束的自监督学习范式，极大拓宽了应用边界。

进入“基础模型”时代以来，单目深度估计正经历从特定场景拟合向零样本泛化（Zero-shot Generalization）的范式转变。 
以 Depth Anything\cite{depthanything} 和 Metric3D\cite{metric3d} 为代表的工作，通过大规模弱监督预训练与数据蒸馏技术，
证明了利用海量无标签数据学习稳健几何表示的可能性。
然而，即便在基础模型的支撑下，现有的绝对深度估计工作仍面临以下严峻挑战：

首先，模型对相机内参及场景分布存在深层的“尺度-语义耦合”误区。 现有的绝对深度预测框架往往将场景几何结构与物理尺度混合建模，
导致模型倾向于通过“背诵”训练集中特定相机的成像特性（如焦距、安装高度）以及常见物体的先验尺寸（如车辆、人高）来推断距离，
而非基于纯粹的投影几何关系。这种统计过拟合（Statistical Overfitting）导致模型极易受到单目歧义性的干扰：
一旦测试环境的焦距或传感器尺寸发生变化，预测结果便会产生剧烈的尺度漂移，无法实现真正的物理一致性。

其次，现有工作对相对深度所蕴含的稳健几何先验利用不足。 从数学本质上看，绝对深度预测是一个受限于相机内参的“病态问题”，
而相对深度由于具备尺度不变性（Scale-invariant），在捕捉物体边缘、空间拓扑及遮挡关系方面表现出极强的泛化潜能。遗憾的是，
多数绝对深度研究仍倾向于构建从图像到绝对数值的直接映射（Direct Mapping）。这种“一步到位”的回归范式往往试图让模型同时学习“复杂的几何感知”与“脆弱的绝对回归”，导致模型在面对异质场景时，容易为了拟合数值精度而丧失基本的几何结构约束，产生结构畸变或物体边缘模糊。

目前，如何在高精度度量需求下实现几何结构与绝对尺度的深度解耦与耦合，已成为学术界关注的焦点。 
尽管 ZoeDepth\cite{zoedepth} 等工作尝试引入相对深度特征，但其复杂的端到端训练策略仍难以完全摆脱尺度耦合的影响。
鉴于此，探讨如何将具有强泛化力的相对深度作为“几何基座”，并通过轻量化的映射机制恢复物理尺度，
对于构建全天候、高可靠的无人系统具有重要的学术意义与应用价值。

% \begin{table}[!ht] % H 表示强制固定在这里，依赖你加载的 float 包
%   \centering
%   \caption{基础三线表示例}
%   \begin{tabular}{llll} % 四个 l 代表四列全部左对齐
%     \toprule
%     方法 & 参数 & 准确率 & 耗时 (s) \\
%     \midrule
%     Baseline  & 128  & 85.2\% & 12.5 \\
%     Ours      & 256  & 92.4\% & 18.2 \\
%     Improved  & 512  & 94.1\% & 25.0 \\
%     \bottomrule
%   \end{tabular}
% \end{table}


